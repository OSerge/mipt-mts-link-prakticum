# Отчёт: Модель Next Best Offer (NBO)

## Задача

Построить систему персонализированных рекомендаций продуктов для клиентов МТС Линк без использования прогноза LTV.

**Бизнес-цель:** Повысить конверсию и выручку за счёт предложения клиенту наиболее релевантного продукта в нужный момент.


## Подход

Вместо прогнозирования LTV (который показал плохие результаты) мы решили задачу как **классификацию**: предсказать, какой продукт клиент купит следующим.

### Данные
- 14,702 транзакции от 2,121 компании (всего в базе)
- 1,681 компания с достаточной историей для рекомендаций
- 26 уникальных продуктов в каталоге
- Период: 2014–2023 гг.

### Признаки
- **История покупок:** предыдущий продукт, тип сделки, дней с прошлой покупки
- **RFM-метрики:** частота, сумма покупок, давность, возраст клиента
- **Поведение:** количество возвратов, новых покупок, продлений, расширений
- **Данные компании:** сектор, сегмент, размер

### Модель

**LightGBM** (Light Gradient Boosting Machine) — алгоритм градиентного бустинга, оптимизированный для скорости и эффективности работы с категориальными признаками.

#### Гиперпараметры

| Параметр | Значение | Описание |
|----------|----------|----------|
| `objective` | multiclass | Многоклассовая классификация |
| `num_class` | 26 | Количество продуктов (классов) |
| `learning_rate` | 0.05 | Скорость обучения |
| `n_estimators` | 400 | Максимальное число деревьев |
| `num_leaves` | 63 | Листьев в дереве |
| `subsample` | 0.9 | Доля строк для обучения дерева |
| `colsample_bytree` | 0.8 | Доля признаков для обучения дерева |
| `early_stopping_rounds` | 30 | Остановка при отсутствии улучшения |

**Фактическое число деревьев:** 43 (early stopping сработал раньше 400)

#### Разделение данных

| Выборка | Период | Размер |
|---------|--------|--------|
| Train | до 2023-01-01 | 13,481 примеров |
| Validation | после 2023-01-01 | 1,221 примеров |

Использован **временной split** — модель обучается на исторических данных и валидируется на будущих, что имитирует реальное применение.

#### Признаки (29 шт.)

**Категориальные (10):**
- `product_name` — текущий продукт
- `prev_product` — предыдущий продукт клиента
- `sale_type`, `prev_sale_type` — тип сделки
- `sector`, `segment`, `industry` — характеристики компании
- `company_size` — размер компании
- `first_purchase`, `last_purchase` — даты первой/последней покупки

**Числовые (19):**
- `days_since_prev` — дней с предыдущей покупки
- `product_sum`, `revenue` — сумма покупки
- `monetary`, `frequency`, `recency` — RFM-метрики
- `customer_age_days` — возраст клиента
- `sale_year`, `sale_month`, `sale_day`, `sale_quarter`, `sale_dayofweek` — временные признаки
- `product_duration`, `n_products` — характеристики продукта
- `Возврат`, `Новая`, `Продление`, `Расширение` — счётчики типов сделок

#### Важность признаков (топ-10)

| Ранг | Признак | Importance | Интерпретация |
|------|---------|------------|---------------|
| 1 | `days_since_prev` | 7,051 | Время с прошлой покупки — ключевой предиктор |
| 2 | `product_sum` | 6,685 | Сумма покупки влияет на выбор продукта |
| 3 | `monetary` | 5,490 | Общая ценность клиента |
| 4 | `sale_day` | 5,363 | День месяца покупки |
| 5 | `revenue` | 5,114 | Выручка от сделки |
| 6 | `customer_age_days` | 4,591 | Как давно клиент с нами |
| 7 | `recency` | 4,375 | Давность последней покупки |
| 8 | `sale_month` | 4,068 | Месяц покупки (сезонность) |
| 9 | `sale_dayofweek` | 3,837 | День недели |
| 10 | `sale_year` | 3,643 | Год покупки (тренды) |

**Вывод:** Модель опирается на поведенческие признаки (время между покупками, суммы) и RFM-метрики, а не только на предыдущий продукт.


## Результаты

### Качество модели

| Метрика | Значение | Комментарий |
|---------|----------|-------------|
| **Top-1 Accuracy** | 64.3% | В 64% случаев угадываем точный продукт |
| **Top-3 Accuracy** | 90.7% | В 91% случаев верный продукт в топ-3 |
| **MAP@3** | 0.767 | Средняя обратная позиция верного продукта в топ-3 |
| **Expected Profit@3** | 13,192 ₽ | Средняя ожидаемая выручка по топ-3 рекомендациям |

**MAP@3 (Mean Average Precision at 3)** — метрика качества ранжирования, которая учитывает не только факт попадания правильного продукта в топ-3, но и его позицию:
- Если правильный продукт на 1-й позиции, то `gain = 1.0`
- Если на 2-й позиции, то `gain = 0.5`
- Если на 3-й позиции, то `gain = 0.33`
- Если не попал в топ-3, то `gain = 0.0`

`MAP@3 = 0.767` означает, что в среднем правильный продукт находится на позиции `~1.3`, что говорит о высоком качестве ранжирования: модель не только находит правильный продукт, но и ставит его на высокие позиции.

### Сравнение с baseline

#### Исторически топ-3 популярных продуктов (train)
1. Расширения: 41.5%
2. Тарифы Webinar СМБ: 36.8%
3. Enterprise-300: 2.9%

#### Сводная таблица

| Метод | Top-1 Accuracy | Top-3 Accuracy | MAP@3 | Expected Profit@3 |
|-------|----------------|----------------|-------|-------------------|
| Случайный выбор | 3.8% | 11.5% | 0.038 | 4,089 ₽ |
| **Топ-3 популярных** | **48.6%** | **78.7%** | **0.634** | **9,681 ₽** |
| **LightGBM (модель)** | **64.3%** | **90.7%** | **0.767** | **13,192 ₽** |

#### Lift модели над бейзлайнами

| Сравнение | Top-1 | Top-3 | MAP@3 | Expected Profit |
|-----------|-------|-------|-------|-----------------|
| vs Случайный выбор | 16.7x | 7.9x | 20.2x | 3.2x |
| vs Топ-3 популярных | 1.32x (+15.6%) | 1.15x (+12.0%) | 1.21x | 1.36x |

**Важно:** Popularity baseline (рекомендовать всем топ-3 популярных продукта) уже даёт **78.7%** Top-3 Accuracy благодаря сильному дисбалансу классов (топ-3 продукта покрывают ~81% всех покупок). Однако модель LightGBM всё равно превосходит его на **+12%** по Top-3 Accuracy и на **+36%** по ожидаемой выручке за счёт персонализации рекомендаций.

### Качество по сегментам

| Сегмент | Top-3 Accuracy |
|---------|----------------|
| High-value клиенты (топ 25%) | **94.1%** |
| Остальные клиенты | 89.6% |

Для ценных клиентов модель работает ещё лучше.


## Что получили на выходе

Для каждой из **1,681 компании** с достаточной историей покупок сформированы персональные рекомендации:

| Поле | Описание |
|------|----------|
| `company_id` | ID клиента |
| `rank` | Позиция в рейтинге (1, 2, 3) |
| `offer_product` | Рекомендуемый продукт |
| `prob` | Вероятность покупки |
| `expected_revenue` | Ожидаемая выручка |

Пример:
| company_id | rank | offer_product | prob | expected_revenue |
|------------|------|---------------|------|------------------|
| comp_001eac7794df | 1 | Тарифы Webinar СМБ | 0.98 | 11,322 ₽ |
| comp_001eac7794df | 2 | Расширения | 0.01 | 150 ₽ |
| comp_003be29c3721 | 1 | МТС Линк. Корпорация | 0.64 | 16,656 ₽ |


## Ключевые выводы

1. **Модель работает хорошо** — Top-3 Accuracy 90.7% означает, что в 9 из 10 случаев верный продукт попадает в топ-3 рекомендаций.

2. **Персонализация даёт реальный прирост.** Даже по сравнению с сильным popularity baseline (топ-3 популярных продуктов, 78.7% Top-3 Accuracy), модель LightGBM показывает прирост **+12%** по точности и **+36%** по ожидаемой выручке.

3. **Главный предиктор — предыдущий продукт.** Клиенты склонны покупать те же или смежные продукты.

4. **Сильный дисбаланс:** ~81% покупок — это топ-3 продукта ("Расширения", "Тарифы Webinar СМБ", "Enterprise-300"). Это объясняет высокое качество popularity baseline, но модель учитывает индивидуальные паттерны.

5. **High-value клиенты предсказуемее** — для них Top-3 Accuracy достигает 94%.

6. **Coverage 73%** — модель рекомендует 19 из 26 продуктов. Редкие Enterprise-тарифы не попадают в рекомендации из-за малого количества данных.

7. **440 компаний без рекомендаций** — для них недостаточно истории покупок (только одна транзакция). Для таких клиентов можно использовать fallback-стратегию: рекомендовать топ-3 популярных продуктов. Это позволит покрыть 100% клиентской базы с качеством 78.7% Top-3 Accuracy.


## Рекомендации по внедрению

1. **Провести A/B тест** — измерить реальный lift в конверсии и выручке.

2. **Интегрировать в CRM** — показывать менеджерам топ-3 оффера при работе с клиентом.

3. **Добавить бизнес-правила:**
   - Не предлагать продукт, который клиент уже купил
   - Учитывать сезонность и акции
   - Ограничить частоту контактов

4. **Мониторинг качества** — отслеживать метрики и переобучать модель при деградации.


## Файлы

- `CDA/nbo.ipynb` — ноутбук с моделью и анализом
- `CDA/nbo_recs.csv` — файл с рекомендациями для всех клиентов

